{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction The Application Gateway Ingress Controller allows Azure Application Gateway to be used as the ingress for an Azure Kubernetes Service aka AKS cluster. As shown in the figure below, the ingress controller runs as a pod within the AKS cluster. It consumes Kubernetes Ingress Resources and converts them to an Azure Application Gateway configuration which allows the gateway to load-balance traffic to Kubernetes pods. Reporting Issues The best way to report an issue is to create a Github Issue for the project. Please include the following information when creating the issue: Subscription ID for AKS cluster. Subscription ID for Application Gateway. AKS cluster name/ARM Resource ID. Application Gateway name/ARM Resource ID. Ingress resource definition that might causing the problem. The Helm configuration used to install the ingress controller.","title":"Introduction"},{"location":"#introduction","text":"The Application Gateway Ingress Controller allows Azure Application Gateway to be used as the ingress for an Azure Kubernetes Service aka AKS cluster. As shown in the figure below, the ingress controller runs as a pod within the AKS cluster. It consumes Kubernetes Ingress Resources and converts them to an Azure Application Gateway configuration which allows the gateway to load-balance traffic to Kubernetes pods.","title":"Introduction"},{"location":"#reporting-issues","text":"The best way to report an issue is to create a Github Issue for the project. Please include the following information when creating the issue: Subscription ID for AKS cluster. Subscription ID for Application Gateway. AKS cluster name/ARM Resource ID. Application Gateway name/ARM Resource ID. Ingress resource definition that might causing the problem. The Helm configuration used to install the ingress controller.","title":"Reporting Issues"},{"location":"annotations/","text":"Annotations Introductions Kubernetes Ingress specification allows for annotations. We use annotations to expose Application Gateway specific features that can't be exposed using the ingress specification. It is important to note that annotations defined on an ingress resource are applied to all HTTP setting, backend pools and listeners defined within a given ingress resource. List of supported annotations Annotation Key Value Type Default Value appgw.ingress.kubernetes.io/backend-path-prefix string nil appgw.ingress.kubernetes.io/ssl-redirect bool false appgw.ingress.kubernetes.io/connection-draining bool false appgw.ingress.kubernetes.io/connection-draining-timeout int32 (seconds) 30 appgw.ingress.kubernetes.io/cookie-based-affinity bool false appgw.ingress.kubernetes.io/request-timeout int32 (seconds) 30 Backend Path Prefix This annotation allows the backend path specified in an ingress resource to be re-written with prefix specified in this annotation. This allows users to expose services whose endpoints are different than endpoint names used to expose a service in an ingress resource. Usage appgw.ingress.kubernetes.io/backend-path-prefix: <path prefix> Example apiVersion: extensions/v1beta1 kind: Ingress metadata: name: go-server-ingress-bkprefix namespace: test-ag annotations: kubernetes.io/ingress.class: azure/application-gateway appgw.ingress.kubernetes.io/backend-path-prefix: \"/test/\" spec: rules: - http: paths: - path: /hello/ backend: serviceName: go-server-service servicePort: 80 In the example above we have defined an ingress resource named go-server-ingress-bkprefix with an annotation appgw.ingress.kubernetes.io/backend-path-prefix: \"/test/\" . The annotation tells application gateway to create an HTTP setting which will have a path prefix override for the path /hello to /test/ . NOTE: In the above example we have only one rule defined. However, the annotations is applicable to the entire ingress resource so if a user had defined multiple rules the backend path prefix would be setup for each of the paths sepcified. Thus, if a user wants different rules with different path prefixes (even for the same service) they would need to define different ingress resources. SSL Redirect Application Gateway can be configured to automatically redirect HTTP URLs to their HTTPS counterparts. When this annotation is present and TLS is properly configured, Kubernetes Ingress controller will create a routing rule with a redirection configuration and apply the changes to your App Gateway. The redirect created will be HTTP 301 Moved Permanently . Usage appgw.ingress.kubernetes.io/ssl-redirect: \"true\" Example apiVersion: extensions/v1beta1 kind: Ingress metadata: name: go-server-ingress-redirect namespace: test-tag annotations: kubernetes.io/ingress.class: azure/application-gateway appgw.ingress.kubernetes.io/ssl-redirect: \"true\" spec: tls: - hosts: - www.contoso.com secretName: testsecret-tls rules: - host: www.contoso.com http: paths: - backend: serviceName: websocket-repeater servicePort: 80 Connection Draining connection-draining : This annotation allows to specify whether to enable connection draining. connection-draining-timeout : This annotation allows to specify a timeout after which Application Gateway will terminate the requests to the draining backend endpoint. Usage appgw.ingress.kubernetes.io/connection-draining: \"true\" appgw.ingress.kubernetes.io/connection-draining-timeout: 60 Example apiVersion: extensions/v1beta1 kind: Ingress metadata: name: go-server-ingress-drain namespace: test-ag annotations: kubernetes.io/ingress.class: azure/application-gateway appgw.ingress.kubernetes.io/connection-draining: \"true\" appgw.ingress.kubernetes.io/connection-draining-timeout: 60 spec: rules: - http: paths: - path: /hello/ backend: serviceName: go-server-service servicePort: 80 Cookie Based Affinity This annotation allows to specify whether to enable cookie based affinity. Usage appgw.ingress.kubernetes.io/cookie-based-affinity: \"true\" Example apiVersion: extensions/v1beta1 kind: Ingress metadata: name: go-server-ingress-affinity namespace: test-ag annotations: kubernetes.io/ingress.class: azure/application-gateway appgw.ingress.kubernetes.io/cookie-based-affinity: \"true\" spec: rules: - http: paths: - path: /hello/ backend: serviceName: go-server-service servicePort: 80 Request Timeout This annotation allows to specify the request timeout in seconds after which Application Gateway will fail the request if response is not received. Usage appgw.ingress.kubernetes.io/request-timeout: 20 Example apiVersion: extensions/v1beta1 kind: Ingress metadata: name: go-server-ingress-timeout namespace: test-ag annotations: kubernetes.io/ingress.class: azure/application-gateway appgw.ingress.kubernetes.io/request-timeout: 20 spec: rules: - http: paths: - path: /hello/ backend: serviceName: go-server-service servicePort: 80","title":"Annotations"},{"location":"annotations/#annotations","text":"","title":"Annotations"},{"location":"annotations/#introductions","text":"Kubernetes Ingress specification allows for annotations. We use annotations to expose Application Gateway specific features that can't be exposed using the ingress specification. It is important to note that annotations defined on an ingress resource are applied to all HTTP setting, backend pools and listeners defined within a given ingress resource.","title":"Introductions"},{"location":"annotations/#list-of-supported-annotations","text":"Annotation Key Value Type Default Value appgw.ingress.kubernetes.io/backend-path-prefix string nil appgw.ingress.kubernetes.io/ssl-redirect bool false appgw.ingress.kubernetes.io/connection-draining bool false appgw.ingress.kubernetes.io/connection-draining-timeout int32 (seconds) 30 appgw.ingress.kubernetes.io/cookie-based-affinity bool false appgw.ingress.kubernetes.io/request-timeout int32 (seconds) 30","title":"List of supported annotations"},{"location":"annotations/#backend-path-prefix","text":"This annotation allows the backend path specified in an ingress resource to be re-written with prefix specified in this annotation. This allows users to expose services whose endpoints are different than endpoint names used to expose a service in an ingress resource.","title":"Backend Path Prefix"},{"location":"annotations/#usage","text":"appgw.ingress.kubernetes.io/backend-path-prefix: <path prefix>","title":"Usage"},{"location":"annotations/#example","text":"apiVersion: extensions/v1beta1 kind: Ingress metadata: name: go-server-ingress-bkprefix namespace: test-ag annotations: kubernetes.io/ingress.class: azure/application-gateway appgw.ingress.kubernetes.io/backend-path-prefix: \"/test/\" spec: rules: - http: paths: - path: /hello/ backend: serviceName: go-server-service servicePort: 80 In the example above we have defined an ingress resource named go-server-ingress-bkprefix with an annotation appgw.ingress.kubernetes.io/backend-path-prefix: \"/test/\" . The annotation tells application gateway to create an HTTP setting which will have a path prefix override for the path /hello to /test/ . NOTE: In the above example we have only one rule defined. However, the annotations is applicable to the entire ingress resource so if a user had defined multiple rules the backend path prefix would be setup for each of the paths sepcified. Thus, if a user wants different rules with different path prefixes (even for the same service) they would need to define different ingress resources.","title":"Example"},{"location":"annotations/#ssl-redirect","text":"Application Gateway can be configured to automatically redirect HTTP URLs to their HTTPS counterparts. When this annotation is present and TLS is properly configured, Kubernetes Ingress controller will create a routing rule with a redirection configuration and apply the changes to your App Gateway. The redirect created will be HTTP 301 Moved Permanently .","title":"SSL Redirect"},{"location":"annotations/#usage_1","text":"appgw.ingress.kubernetes.io/ssl-redirect: \"true\"","title":"Usage"},{"location":"annotations/#example_1","text":"apiVersion: extensions/v1beta1 kind: Ingress metadata: name: go-server-ingress-redirect namespace: test-tag annotations: kubernetes.io/ingress.class: azure/application-gateway appgw.ingress.kubernetes.io/ssl-redirect: \"true\" spec: tls: - hosts: - www.contoso.com secretName: testsecret-tls rules: - host: www.contoso.com http: paths: - backend: serviceName: websocket-repeater servicePort: 80","title":"Example"},{"location":"annotations/#connection-draining","text":"connection-draining : This annotation allows to specify whether to enable connection draining. connection-draining-timeout : This annotation allows to specify a timeout after which Application Gateway will terminate the requests to the draining backend endpoint.","title":"Connection Draining"},{"location":"annotations/#usage_2","text":"appgw.ingress.kubernetes.io/connection-draining: \"true\" appgw.ingress.kubernetes.io/connection-draining-timeout: 60","title":"Usage"},{"location":"annotations/#example_2","text":"apiVersion: extensions/v1beta1 kind: Ingress metadata: name: go-server-ingress-drain namespace: test-ag annotations: kubernetes.io/ingress.class: azure/application-gateway appgw.ingress.kubernetes.io/connection-draining: \"true\" appgw.ingress.kubernetes.io/connection-draining-timeout: 60 spec: rules: - http: paths: - path: /hello/ backend: serviceName: go-server-service servicePort: 80","title":"Example"},{"location":"annotations/#cookie-based-affinity","text":"This annotation allows to specify whether to enable cookie based affinity.","title":"Cookie Based Affinity"},{"location":"annotations/#usage_3","text":"appgw.ingress.kubernetes.io/cookie-based-affinity: \"true\"","title":"Usage"},{"location":"annotations/#example_3","text":"apiVersion: extensions/v1beta1 kind: Ingress metadata: name: go-server-ingress-affinity namespace: test-ag annotations: kubernetes.io/ingress.class: azure/application-gateway appgw.ingress.kubernetes.io/cookie-based-affinity: \"true\" spec: rules: - http: paths: - path: /hello/ backend: serviceName: go-server-service servicePort: 80","title":"Example"},{"location":"annotations/#request-timeout","text":"This annotation allows to specify the request timeout in seconds after which Application Gateway will fail the request if response is not received.","title":"Request Timeout"},{"location":"annotations/#usage_4","text":"appgw.ingress.kubernetes.io/request-timeout: 20","title":"Usage"},{"location":"annotations/#example_4","text":"apiVersion: extensions/v1beta1 kind: Ingress metadata: name: go-server-ingress-timeout namespace: test-ag annotations: kubernetes.io/ingress.class: azure/application-gateway appgw.ingress.kubernetes.io/request-timeout: 20 spec: rules: - http: paths: - path: /hello/ backend: serviceName: go-server-service servicePort: 80","title":"Example"},{"location":"faq/","text":"Frequrently Asked Questions: [WIP] What is an Ingress Controller Can single ingress controller instance manage multiple Application Gateway What is an Ingress Controller Kubernetes allows creation of deployment and service resource to expose a group of pods internally in the cluster. To expose the same service externally, an Ingress resource is defined which provides load balancing, SSL termination and name-based virtual hosting. To satify this Ingress resource, an Ingress Controller is required which listens for any changes to Ingress resources and configures the load balancer policies. The Application Gateway Ingress Controller allows Azure Application Gateway to be used as the ingress for an Azure Kubernetes Service aka AKS cluster. Can single ingress controller instance manage multiple Application Gateway Currently, One instance of Ingress Controller can only be associated to one Application Gateway.","title":"Frequrently Asked Questions: [WIP]"},{"location":"faq/#frequrently-asked-questions-wip","text":"What is an Ingress Controller Can single ingress controller instance manage multiple Application Gateway","title":"Frequrently Asked Questions: [WIP]"},{"location":"faq/#what-is-an-ingress-controller","text":"Kubernetes allows creation of deployment and service resource to expose a group of pods internally in the cluster. To expose the same service externally, an Ingress resource is defined which provides load balancing, SSL termination and name-based virtual hosting. To satify this Ingress resource, an Ingress Controller is required which listens for any changes to Ingress resources and configures the load balancer policies. The Application Gateway Ingress Controller allows Azure Application Gateway to be used as the ingress for an Azure Kubernetes Service aka AKS cluster.","title":"What is an Ingress Controller"},{"location":"faq/#can-single-ingress-controller-instance-manage-multiple-application-gateway","text":"Currently, One instance of Ingress Controller can only be associated to one Application Gateway.","title":"Can single ingress controller instance manage multiple Application Gateway"},{"location":"troubleshooting/","text":"Troubleshooting The Application Gateway Ingress Controller relies primarily on the Kubernetes Service and Ingress resources to construct configuration for App Gateway. Surprising AGIC behavior (or none at all) could be as a result of missing or incorrect configuration. Get the existing namespaces in Kubernetes cluster. What namespace is your app running in? Is AGIC watching that namespace? Refer to the Multiple Namespace Support documentation on how to properly configure observed namespaces. # What namespaces exist on your cluster kubectl get namespaces # What pods are currently running kubectl get pods --all-namespaces -o wide The AGIC pod should be in the default namespace (see column NAMESPACE ). A healthy pod would have Running in the STATUS column. There should be at least one AGIC pod. # Get a list of the Application Gateway Ingress Controller pods kubectl get pods --all-namespaces --selector app=ingress-azure If the AGIC pod is not healthy ( STATUS column from the command above is not Running ): get logs to understand why: kubectl logs <pod-name> for the previous instance of the pod: kubectl logs <pod-name> --previous describe the pod to get more context: kubectl describe pod <pod-name> Do you have a Kubernetes Service and Ingress resources? # Get all services across all namespaces kubectl get service --all-namespaces -o wide # Get all ingress resources across all namespaces kubectl get ingress --all-namespaces -o wide Is your Ingress annotated with: kubernetes.io/ingress.class: azure/application-gateway ? AGIC will only watch for Kubernetes Ingress resources that have this annotation. # Get the YAML definition of a particular ingress resource kubectl get ingress --namespace <which-namespace?> <which-ingress?> -o yaml AGIC emits Kubernetes events for certain critical errors. You can view these: in your terminal via kubectl get events --sort-by=.metadata.creationTimestamp in your browser using the Kubernetes Web UI (Dashboard) Logging Levels AGIC has 3 logging levels. Level 1 is the default one and it shows minimal number of log lines. Level 5, on the other hand, would display all logs, including sanitized contents of config applied to ARM. The Kubernetes community has established 9 levels of logging for the kubectl tool. In this repository we are utilizing 3 of these, with similar semantics: Verbosity Description 1 Default log level; shows startup details, warnings and errors 3 Extended information about events and changes; lists of created objects 5 Logs marshaled objects; shows sanitized JSON config applied to ARM The verbosity levels are adjustable via the verbosityLevel variable in the helm-config.yaml file. Increase verbosity level to 5 to get the JSON config dispatched to ARM : - add verbosityLevel: 5 on a line by itself in helm-config.yaml and re-install - get logs with kubectl logs <pod-name>","title":"Troubleshooting"},{"location":"troubleshooting/#troubleshooting","text":"The Application Gateway Ingress Controller relies primarily on the Kubernetes Service and Ingress resources to construct configuration for App Gateway. Surprising AGIC behavior (or none at all) could be as a result of missing or incorrect configuration. Get the existing namespaces in Kubernetes cluster. What namespace is your app running in? Is AGIC watching that namespace? Refer to the Multiple Namespace Support documentation on how to properly configure observed namespaces. # What namespaces exist on your cluster kubectl get namespaces # What pods are currently running kubectl get pods --all-namespaces -o wide The AGIC pod should be in the default namespace (see column NAMESPACE ). A healthy pod would have Running in the STATUS column. There should be at least one AGIC pod. # Get a list of the Application Gateway Ingress Controller pods kubectl get pods --all-namespaces --selector app=ingress-azure If the AGIC pod is not healthy ( STATUS column from the command above is not Running ): get logs to understand why: kubectl logs <pod-name> for the previous instance of the pod: kubectl logs <pod-name> --previous describe the pod to get more context: kubectl describe pod <pod-name> Do you have a Kubernetes Service and Ingress resources? # Get all services across all namespaces kubectl get service --all-namespaces -o wide # Get all ingress resources across all namespaces kubectl get ingress --all-namespaces -o wide Is your Ingress annotated with: kubernetes.io/ingress.class: azure/application-gateway ? AGIC will only watch for Kubernetes Ingress resources that have this annotation. # Get the YAML definition of a particular ingress resource kubectl get ingress --namespace <which-namespace?> <which-ingress?> -o yaml AGIC emits Kubernetes events for certain critical errors. You can view these: in your terminal via kubectl get events --sort-by=.metadata.creationTimestamp in your browser using the Kubernetes Web UI (Dashboard)","title":"Troubleshooting"},{"location":"troubleshooting/#logging-levels","text":"AGIC has 3 logging levels. Level 1 is the default one and it shows minimal number of log lines. Level 5, on the other hand, would display all logs, including sanitized contents of config applied to ARM. The Kubernetes community has established 9 levels of logging for the kubectl tool. In this repository we are utilizing 3 of these, with similar semantics: Verbosity Description 1 Default log level; shows startup details, warnings and errors 3 Extended information about events and changes; lists of created objects 5 Logs marshaled objects; shows sanitized JSON config applied to ARM The verbosity levels are adjustable via the verbosityLevel variable in the helm-config.yaml file. Increase verbosity level to 5 to get the JSON config dispatched to ARM : - add verbosityLevel: 5 on a line by itself in helm-config.yaml and re-install - get logs with kubectl logs <pod-name>","title":"Logging Levels"},{"location":"tutorial/","text":"Tutorials These tutorials help illustrate the usage of Kubernetes Ingress Resources to expose an example Kubernetes service through the Azure Application Gateway over HTTP or HTTPS. Table of Contents Prerequisites Deploy guestbook application Expose services over HTTP Expose services over HTTPS Without specified hostname With specified hostname Integrate with other services Prerequisites Installed ingress-azure helm chart. Greenfield Deployment : If you are starting from scratch, refer to these installation instructions which outlines steps to deploy an AKS cluster with Application Gateway and install application gateway ingress controller on the AKS cluster. Brownfield Deployment : If you have an existing AKS cluster and Application Gateway, refer to these instructions to install application gateway ingress controller on the AKS cluster. If you want to use HTTPS on this application, you will need a x509 certificate and its private key. Deploy guestbook application The guestbook application is a canonical Kubernetes application that composes of a Web UI frontend, a backend and a Redis database. By default, guestbook exposes its application through a service with name frontend on port 80 . Without a Kubernetes Ingress Resource the service is not accessible from outside the AKS cluster. We will use the application and setup Ingress Resources to access the application through HTTP and HTTPS. Follow the instructions below to deploy the guestbook application. Download guestbook-all-in-one.yaml from here Deploy guestbook-all-in-one.yaml into your AKS cluster by running kubectl apply -f guestbook-all-in-one.yaml Now, the guestbook application has been deployed. Expose services over HTTP In order to expose the guestbook application we will using the following ingress resource: apiVersion: extensions/v1beta1 kind: Ingress metadata: name: guestbook annotations: kubernetes.io/ingress.class: azure/application-gateway spec: rules: - http: paths: - backend: serviceName: frontend servicePort: 80 This ingress will expose the frontend service of the guestbook-all-in-one deployment as a default backend of the Application Gateway. Save the above ingress resource as ing-guestbook.yaml . Deploy ing-guestbook.yaml by running: kubectl apply -f ing-guestbook.yaml Check the log of the ingress controller for deployment status. Now the guestbook application should be available. You can check this by visiting the public address of the Application Gateway. Expose services over HTTPS Without specified hostname Without specifying hostname, the guestbook service will be available on all the host-names pointing to the application gateway. Before deploying ingress, you need to create a kubernetes secret to host the certificate and private key. You can create a kubernetes secret by running kubectl create secret tls <guestbook-secret-name> --key <path-to-key> --cert <path-to-cert> Define the following ingress. In the ingress, specify the name of the secret in the secretName section. apiVersion: extensions/v1beta1 kind: Ingress metadata: name: guestbook annotations: kubernetes.io/ingress.class: azure/application-gateway spec: tls: - secretName: <guestbook-secret-name> rules: - http: paths: - backend: serviceName: frontend servicePort: 80 NOTE: Replace <guestbook-secret-name> in the above Ingress Resource with the name of your secret. Store the above Ingress Resource in a file name ing-guestbook-tls.yaml . Deploy ing-guestbook-tls.yaml by running kubectl apply -f ing-guestbook-tls.yaml Check the log of the ingress controller for deployment status. Now the guestbook application will be available on both HTTP and HTTPS. With specified hostname You can also specify the hostname on the ingress in order to multiplex TLS configurations and services. By specifying hostname, the guestbook service will only be available on the specified host. Define the following ingress. In the ingress, specify the name of the secret in the secretName section and replace the hostname in the hosts section accordingly. apiVersion: extensions/v1beta1 kind: Ingress metadata: name: guestbook annotations: kubernetes.io/ingress.class: azure/application-gateway spec: tls: - hosts: - <guestbook.contoso.com> secretName: <guestbook-secret-name> rules: - host: <guestbook.contoso.com> http: paths: - backend: serviceName: frontend servicePort: 80 Deploy ing-guestbook-tls-sni.yaml by running kubectl apply -f ing-guestbook-tls-sni.yaml Check the log of the ingress controller for deployment status. Now the guestbook application will be available on both HTTP and HTTPS only on the specified host ( <guestbook.contoso.com> in this example). Integrate with other services The following ingress will allow you to add additional paths into this ingress and redirect those paths to other services: ```yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: guestbook annotations: kubernetes.io/ingress.class: azure/application-gateway spec: rules: - http: paths: - path: </other/*> backend: serviceName: <other-service> servicePort: 80 - backend: serviceName: frontend servicePort: 80 ```","title":"Tutorials"},{"location":"tutorial/#tutorials","text":"These tutorials help illustrate the usage of Kubernetes Ingress Resources to expose an example Kubernetes service through the Azure Application Gateway over HTTP or HTTPS.","title":"Tutorials"},{"location":"tutorial/#table-of-contents","text":"Prerequisites Deploy guestbook application Expose services over HTTP Expose services over HTTPS Without specified hostname With specified hostname Integrate with other services","title":"Table of Contents"},{"location":"tutorial/#prerequisites","text":"Installed ingress-azure helm chart. Greenfield Deployment : If you are starting from scratch, refer to these installation instructions which outlines steps to deploy an AKS cluster with Application Gateway and install application gateway ingress controller on the AKS cluster. Brownfield Deployment : If you have an existing AKS cluster and Application Gateway, refer to these instructions to install application gateway ingress controller on the AKS cluster. If you want to use HTTPS on this application, you will need a x509 certificate and its private key.","title":"Prerequisites"},{"location":"tutorial/#deploy-guestbook-application","text":"The guestbook application is a canonical Kubernetes application that composes of a Web UI frontend, a backend and a Redis database. By default, guestbook exposes its application through a service with name frontend on port 80 . Without a Kubernetes Ingress Resource the service is not accessible from outside the AKS cluster. We will use the application and setup Ingress Resources to access the application through HTTP and HTTPS. Follow the instructions below to deploy the guestbook application. Download guestbook-all-in-one.yaml from here Deploy guestbook-all-in-one.yaml into your AKS cluster by running kubectl apply -f guestbook-all-in-one.yaml Now, the guestbook application has been deployed.","title":"Deploy guestbook application"},{"location":"tutorial/#expose-services-over-http","text":"In order to expose the guestbook application we will using the following ingress resource: apiVersion: extensions/v1beta1 kind: Ingress metadata: name: guestbook annotations: kubernetes.io/ingress.class: azure/application-gateway spec: rules: - http: paths: - backend: serviceName: frontend servicePort: 80 This ingress will expose the frontend service of the guestbook-all-in-one deployment as a default backend of the Application Gateway. Save the above ingress resource as ing-guestbook.yaml . Deploy ing-guestbook.yaml by running: kubectl apply -f ing-guestbook.yaml Check the log of the ingress controller for deployment status. Now the guestbook application should be available. You can check this by visiting the public address of the Application Gateway.","title":"Expose services over HTTP"},{"location":"tutorial/#expose-services-over-https","text":"","title":"Expose services over HTTPS"},{"location":"tutorial/#without-specified-hostname","text":"Without specifying hostname, the guestbook service will be available on all the host-names pointing to the application gateway. Before deploying ingress, you need to create a kubernetes secret to host the certificate and private key. You can create a kubernetes secret by running kubectl create secret tls <guestbook-secret-name> --key <path-to-key> --cert <path-to-cert> Define the following ingress. In the ingress, specify the name of the secret in the secretName section. apiVersion: extensions/v1beta1 kind: Ingress metadata: name: guestbook annotations: kubernetes.io/ingress.class: azure/application-gateway spec: tls: - secretName: <guestbook-secret-name> rules: - http: paths: - backend: serviceName: frontend servicePort: 80 NOTE: Replace <guestbook-secret-name> in the above Ingress Resource with the name of your secret. Store the above Ingress Resource in a file name ing-guestbook-tls.yaml . Deploy ing-guestbook-tls.yaml by running kubectl apply -f ing-guestbook-tls.yaml Check the log of the ingress controller for deployment status. Now the guestbook application will be available on both HTTP and HTTPS.","title":"Without specified hostname"},{"location":"tutorial/#with-specified-hostname","text":"You can also specify the hostname on the ingress in order to multiplex TLS configurations and services. By specifying hostname, the guestbook service will only be available on the specified host. Define the following ingress. In the ingress, specify the name of the secret in the secretName section and replace the hostname in the hosts section accordingly. apiVersion: extensions/v1beta1 kind: Ingress metadata: name: guestbook annotations: kubernetes.io/ingress.class: azure/application-gateway spec: tls: - hosts: - <guestbook.contoso.com> secretName: <guestbook-secret-name> rules: - host: <guestbook.contoso.com> http: paths: - backend: serviceName: frontend servicePort: 80 Deploy ing-guestbook-tls-sni.yaml by running kubectl apply -f ing-guestbook-tls-sni.yaml Check the log of the ingress controller for deployment status. Now the guestbook application will be available on both HTTP and HTTPS only on the specified host ( <guestbook.contoso.com> in this example).","title":"With specified hostname"},{"location":"tutorial/#integrate-with-other-services","text":"The following ingress will allow you to add additional paths into this ingress and redirect those paths to other services: ```yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: guestbook annotations: kubernetes.io/ingress.class: azure/application-gateway spec: rules: - http: paths: - path: </other/*> backend: serviceName: <other-service> servicePort: 80 - backend: serviceName: frontend servicePort: 80 ```","title":"Integrate with other services"},{"location":"developers/build/","text":"Building the controller CMake options This is a CMake-based project. Build targets include: ALL_BUILD (default target) builds appgw-ingress and dockerize target devenv builds a docker image with configured development environment vendor installs dependency using go mod in a docker container with image from devenv target appgw-ingress builds the binary for this controller in a docker container with image from devenv target dockerize builds a docker image with the binary from appgw-ingress target dockerpush pushes the docker image to a container registry with prefix defined in CMake variable <deployment_push_prefix> To run the CMake targets: mkdir build && cd build creates and enters a build directory cmake .. generates project configuration in the build directory cmake --build . to build the default target, or cmake --build . --target <target_name> to specify a target to run from above Running it locally This section outlines the environment variables and files necessary to successfully compile and run the Go binary, then connect it to an Azure Kubernetes Service . Obtain Azure Credentials In order to run the Go binary locally and control a remote AKS server, you need Azure credentials. These will be stored in a JSON file in your home directory. Follow these instructions to create the $HOME/.azure/azureAuth.json file. The file is generated via: az ad sp create-for-rbac --subscription <your-azure-subscription-id> --sdk-auth > $HOME/.azure/azureAuth.json The file will contain a JSON blob with the following shape: { \"clientId\": \"...\", \"clientSecret\": \"...\", \"subscriptionId\": \"<your-azure-resource-group>\", \"tenantId\": \"...\", \"activeDirectoryEndpointUrl\": \"https://login.microsoftonline.com\", \"resourceManagerEndpointUrl\": \"https://management.azure.com/\", \"activeDirectoryGraphResourceId\": \"https://graph.windows.net/\", \"sqlManagementEndpointUrl\": \"https://management.core.windows.net:8443/\", \"galleryEndpointUrl\": \"https://gallery.azure.com/\", \"managementEndpointUrl\": \"https://management.core.windows.net/\" } Startup Script In the scripts directory you will find start.sh . This script builds and runs the ingress controller on your local machine and connects to a remote AKS cluster. A .env file in the root of the repository is required. Steps to run ingress controller: Configure: cp .env.example .env and modify the environment variables in .env to match your config Run: ./scripts/start.sh","title":"Building the controller"},{"location":"developers/build/#building-the-controller","text":"","title":"Building the controller"},{"location":"developers/build/#cmake-options","text":"This is a CMake-based project. Build targets include: ALL_BUILD (default target) builds appgw-ingress and dockerize target devenv builds a docker image with configured development environment vendor installs dependency using go mod in a docker container with image from devenv target appgw-ingress builds the binary for this controller in a docker container with image from devenv target dockerize builds a docker image with the binary from appgw-ingress target dockerpush pushes the docker image to a container registry with prefix defined in CMake variable <deployment_push_prefix> To run the CMake targets: mkdir build && cd build creates and enters a build directory cmake .. generates project configuration in the build directory cmake --build . to build the default target, or cmake --build . --target <target_name> to specify a target to run from above","title":"CMake options"},{"location":"developers/build/#running-it-locally","text":"This section outlines the environment variables and files necessary to successfully compile and run the Go binary, then connect it to an Azure Kubernetes Service .","title":"Running it locally"},{"location":"developers/build/#obtain-azure-credentials","text":"In order to run the Go binary locally and control a remote AKS server, you need Azure credentials. These will be stored in a JSON file in your home directory. Follow these instructions to create the $HOME/.azure/azureAuth.json file. The file is generated via: az ad sp create-for-rbac --subscription <your-azure-subscription-id> --sdk-auth > $HOME/.azure/azureAuth.json The file will contain a JSON blob with the following shape: { \"clientId\": \"...\", \"clientSecret\": \"...\", \"subscriptionId\": \"<your-azure-resource-group>\", \"tenantId\": \"...\", \"activeDirectoryEndpointUrl\": \"https://login.microsoftonline.com\", \"resourceManagerEndpointUrl\": \"https://management.azure.com/\", \"activeDirectoryGraphResourceId\": \"https://graph.windows.net/\", \"sqlManagementEndpointUrl\": \"https://management.core.windows.net:8443/\", \"galleryEndpointUrl\": \"https://gallery.azure.com/\", \"managementEndpointUrl\": \"https://management.core.windows.net/\" }","title":"Obtain Azure Credentials"},{"location":"developers/build/#startup-script","text":"In the scripts directory you will find start.sh . This script builds and runs the ingress controller on your local machine and connects to a remote AKS cluster. A .env file in the root of the repository is required. Steps to run ingress controller: Configure: cp .env.example .env and modify the environment variables in .env to match your config Run: ./scripts/start.sh","title":"Startup Script"},{"location":"developers/contribute/","text":"Contribution Guidelines This is a Golang project. You can find the build instructions of the project in the Developer Guide . This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.microsoft.com . When you submit a pull request, a CLA-bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA. This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.","title":"Contribution Guidelines"},{"location":"developers/contribute/#contribution-guidelines","text":"This is a Golang project. You can find the build instructions of the project in the Developer Guide . This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.microsoft.com . When you submit a pull request, a CLA-bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA. This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.","title":"Contribution Guidelines"},{"location":"features/cookie-affinity/","text":"Enable Cookie based Affinity As outlined in the Azure Application Gateway Documentation , Application Gateway supports cookie based affinity enabling which it can direct subsequent traffic from a user session to the same server for processing. Example apiVersion: extensions/v1beta1 kind: Ingress metadata: name: guestbook annotations: kubernetes.io/ingress.class: azure/application-gateway appgw.ingress.kubernetes.io/cookie-based-affinity: \"true\" spec: rules: - http: paths: - backend: serviceName: frontend servicePort: 80","title":"Cookie affinity"},{"location":"features/cookie-affinity/#enable-cookie-based-affinity","text":"As outlined in the Azure Application Gateway Documentation , Application Gateway supports cookie based affinity enabling which it can direct subsequent traffic from a user session to the same server for processing.","title":"Enable Cookie based Affinity"},{"location":"features/cookie-affinity/#example","text":"apiVersion: extensions/v1beta1 kind: Ingress metadata: name: guestbook annotations: kubernetes.io/ingress.class: azure/application-gateway appgw.ingress.kubernetes.io/cookie-based-affinity: \"true\" spec: rules: - http: paths: - backend: serviceName: frontend servicePort: 80","title":"Example"},{"location":"features/multiple-namespaces/","text":"Multiple Namespace Support Motivation Kubernetes Namespaces make it possible for a Kubernetes cluster to be partitioned and allocated to sub-groups of a larger team. These sub-teams can then deploy and manage infrastructure with finer controls of resources, security, configuration etc. Kubernetes allows for one or more ingress resources to be defined independently within each namespace. As of version 0.7 Azure Application Gateway Kubernetes IngressController (AGIC) can ingest events from and observe multiple namespaces. Should the AKS administrator decide to use App Gateway as an ingress, all namespaces will use the same instance of App Gateway. A single installation of Ingress Controller will monitor accessible namespaces and will configure the App Gateway it is associated with. Version 0.7 of AGIC will continue to exclusively observe the default namespace, unless this is explicitly changed to one or more different namespaces in the Helm configuration (see section below). Enable multiple namespace support To enable multiple namespace support: 1. modify the helm-config.yaml file in one of the following ways: - delete the watchNamespace key entirely from helm-config.yaml - AGIC will observe all namespaces - set watchNamespace to an empty string - AGIC will observe all namespaces - add multiple namespaces separated by a comma ( watchNamespace: default,secondNamespace ) - AGIC will observe these namespaces exclusively 2. apply Helm template changes with: helm install -f helm-config.yaml application-gateway-kubernetes-ingress/ingress-azure Once deployed with the ability to observe multiple namespaces, AGIC will: - list ingress resources from all accessible namespaces - filter to ingress resources annotated with kubernetes.io/ingress.class: azure/application-gateway - compose combined App Gateway config - apply the config to the associated App Gateway via ARM Conflicting Configurations Multiple namespaced ingress resources could instruct AGIC to create conflicting configurations for a single App Gateway. (Two ingresses claiming the same domain for instance.) At the top of the hierarchy - listeners (IP address, port, and host) and routing rules (binding listener, backend pool and HTTP settings) could be created and shared by multiple namespaces/ingresses. On the other hand - paths, backend pools, HTTP settings, and TLS certificates could be created by one namespace only and duplicates will removed.. For example, consider the following duplicate ingress resources defined namespaces staging and production for www.contoso.com : apiVersion: extensions/v1beta1 kind: Ingress metadata: name: websocket-ingress namespace: staging annotations: kubernetes.io/ingress.class: azure/application-gateway spec: rules: - host: www.contoso.com http: paths: - backend: serviceName: web-service servicePort: 80 apiVersion: extensions/v1beta1 kind: Ingress metadata: name: websocket-ingress namespace: production annotations: kubernetes.io/ingress.class: azure/application-gateway spec: rules: - host: www.contoso.com http: paths: - backend: serviceName: web-service servicePort: 80 Despite the two ingress resources demanding traffic for www.contoso.com to be routed to the respective Kubernetes namespaces, only one backend can service the traffic. AGIC would create a configuration on \"first come, first served\" basis for one of the resources. If two ingresses resources are created at the same time, the one earlier in the alphabet will take precedence. From the example above we will only be able to create settings for the production ingress. App Gateway will be configured with the following resources: Listener: fl-www.contoso.com-80 Routing Rule: rr-www.contoso.com-80 Backend Pool: pool-production-contoso-web-service-80-bp-80 HTTP Settings: bp-production-contoso-web-service-80-80-websocket-ingress Health Probe: pb-production-contoso-web-service-80-websocket-ingress Note that except for listener and routing rule , the App Gateway resources created include the name of the namespace ( production ) for which they were created. If the two ingress resources are introduced into the AKS cluster at different points in time, it is likely for AGIC to end up in a scenario where it reconfigures App Gateway and re-routes traffic from namespace-B to namespace-A . For example if you added staging first, AGIC will configure App Gwy to route traffic to the staging backend pool. At a later stage, introducing production ingress, will cause AGIC to reprogram App Gwy, which will start routing traffic to the production backend pool. Restricting Access to Namespaces By default AGIC will configure App Gateway based on annotated Ingress within any namespace. Should you want to limit this behaviour you have the following options: - limit the namespaces, by explicitly defining namespaces AGIC should observe via the watchNamespace YAML key in helm-config.yaml - use Role/RoleBinding to limit AGIC to specific namespaces","title":"Multiple Namespace Support"},{"location":"features/multiple-namespaces/#multiple-namespace-support","text":"","title":"Multiple Namespace Support"},{"location":"features/multiple-namespaces/#motivation","text":"Kubernetes Namespaces make it possible for a Kubernetes cluster to be partitioned and allocated to sub-groups of a larger team. These sub-teams can then deploy and manage infrastructure with finer controls of resources, security, configuration etc. Kubernetes allows for one or more ingress resources to be defined independently within each namespace. As of version 0.7 Azure Application Gateway Kubernetes IngressController (AGIC) can ingest events from and observe multiple namespaces. Should the AKS administrator decide to use App Gateway as an ingress, all namespaces will use the same instance of App Gateway. A single installation of Ingress Controller will monitor accessible namespaces and will configure the App Gateway it is associated with. Version 0.7 of AGIC will continue to exclusively observe the default namespace, unless this is explicitly changed to one or more different namespaces in the Helm configuration (see section below).","title":"Motivation"},{"location":"features/multiple-namespaces/#enable-multiple-namespace-support","text":"To enable multiple namespace support: 1. modify the helm-config.yaml file in one of the following ways: - delete the watchNamespace key entirely from helm-config.yaml - AGIC will observe all namespaces - set watchNamespace to an empty string - AGIC will observe all namespaces - add multiple namespaces separated by a comma ( watchNamespace: default,secondNamespace ) - AGIC will observe these namespaces exclusively 2. apply Helm template changes with: helm install -f helm-config.yaml application-gateway-kubernetes-ingress/ingress-azure Once deployed with the ability to observe multiple namespaces, AGIC will: - list ingress resources from all accessible namespaces - filter to ingress resources annotated with kubernetes.io/ingress.class: azure/application-gateway - compose combined App Gateway config - apply the config to the associated App Gateway via ARM","title":"Enable multiple namespace support"},{"location":"features/multiple-namespaces/#conflicting-configurations","text":"Multiple namespaced ingress resources could instruct AGIC to create conflicting configurations for a single App Gateway. (Two ingresses claiming the same domain for instance.) At the top of the hierarchy - listeners (IP address, port, and host) and routing rules (binding listener, backend pool and HTTP settings) could be created and shared by multiple namespaces/ingresses. On the other hand - paths, backend pools, HTTP settings, and TLS certificates could be created by one namespace only and duplicates will removed.. For example, consider the following duplicate ingress resources defined namespaces staging and production for www.contoso.com : apiVersion: extensions/v1beta1 kind: Ingress metadata: name: websocket-ingress namespace: staging annotations: kubernetes.io/ingress.class: azure/application-gateway spec: rules: - host: www.contoso.com http: paths: - backend: serviceName: web-service servicePort: 80 apiVersion: extensions/v1beta1 kind: Ingress metadata: name: websocket-ingress namespace: production annotations: kubernetes.io/ingress.class: azure/application-gateway spec: rules: - host: www.contoso.com http: paths: - backend: serviceName: web-service servicePort: 80 Despite the two ingress resources demanding traffic for www.contoso.com to be routed to the respective Kubernetes namespaces, only one backend can service the traffic. AGIC would create a configuration on \"first come, first served\" basis for one of the resources. If two ingresses resources are created at the same time, the one earlier in the alphabet will take precedence. From the example above we will only be able to create settings for the production ingress. App Gateway will be configured with the following resources: Listener: fl-www.contoso.com-80 Routing Rule: rr-www.contoso.com-80 Backend Pool: pool-production-contoso-web-service-80-bp-80 HTTP Settings: bp-production-contoso-web-service-80-80-websocket-ingress Health Probe: pb-production-contoso-web-service-80-websocket-ingress Note that except for listener and routing rule , the App Gateway resources created include the name of the namespace ( production ) for which they were created. If the two ingress resources are introduced into the AKS cluster at different points in time, it is likely for AGIC to end up in a scenario where it reconfigures App Gateway and re-routes traffic from namespace-B to namespace-A . For example if you added staging first, AGIC will configure App Gwy to route traffic to the staging backend pool. At a later stage, introducing production ingress, will cause AGIC to reprogram App Gwy, which will start routing traffic to the production backend pool.","title":"Conflicting Configurations"},{"location":"features/multiple-namespaces/#restricting-access-to-namespaces","text":"By default AGIC will configure App Gateway based on annotated Ingress within any namespace. Should you want to limit this behaviour you have the following options: - limit the namespaces, by explicitly defining namespaces AGIC should observe via the watchNamespace YAML key in helm-config.yaml - use Role/RoleBinding to limit AGIC to specific namespaces","title":"Restricting Access to Namespaces"},{"location":"features/private-ip/","text":"Using Private IP for internal routing Pre-requisites Application Gateway with a Private IP configuration This feature allows to expose the ingress endpoint within the Virtual Network . To configure the controller to use Private IP for routing, modify the helm config by adding usePrivateIP: true Example appgw: subscriptionId: <subscriptionId> resourceGroup: <resourceGroupName> name: <applicationGatewayName> usePrivateIP: true armAuth: type: aadPodIdentity identityResourceID: <identityResourceId> identityClientID: <identityClientId> This will make the ingress controller filter the ipconfigurations for a Private IP when configuring the frontend listeners on the Application Gateway. Controller will panic and crash if usePrivateIP: true and no Private IP is assigned. Notes: Application Gateway v2 SKU manadates a Public IP. For meeting compliance requirement where the Application Gateway should be completely private, Attach a Network Security Group to the Application Gateway's subnet to restrict traffic. To expose the Ingress both on public and private, current recommedation is to deploy two Application Gateways with respective Ingress Controllers, one with Public IP and one with Private IP.","title":"Using Private IP for internal routing"},{"location":"features/private-ip/#using-private-ip-for-internal-routing","text":"","title":"Using Private IP for internal routing"},{"location":"features/private-ip/#pre-requisites","text":"Application Gateway with a Private IP configuration This feature allows to expose the ingress endpoint within the Virtual Network . To configure the controller to use Private IP for routing, modify the helm config by adding usePrivateIP: true","title":"Pre-requisites"},{"location":"features/private-ip/#example","text":"appgw: subscriptionId: <subscriptionId> resourceGroup: <resourceGroupName> name: <applicationGatewayName> usePrivateIP: true armAuth: type: aadPodIdentity identityResourceID: <identityResourceId> identityClientID: <identityClientId> This will make the ingress controller filter the ipconfigurations for a Private IP when configuring the frontend listeners on the Application Gateway. Controller will panic and crash if usePrivateIP: true and no Private IP is assigned. Notes: Application Gateway v2 SKU manadates a Public IP. For meeting compliance requirement where the Application Gateway should be completely private, Attach a Network Security Group to the Application Gateway's subnet to restrict traffic. To expose the Ingress both on public and private, current recommedation is to deploy two Application Gateways with respective Ingress Controllers, one with Public IP and one with Private IP.","title":"Example"},{"location":"features/probes/","text":"Adding Health Probes to your service By default, Ingress controller will provision an HTTP GET probe for the exposed pods. The probe properties can be customized by adding a Readiness or Liveness Probe to your deployment / pod spec. With readinessProbe or livenessProbe apiVersion: extensions/v1beta1 kind: Deployment metadata: name: aspnetapp spec: replicas: 3 template: metadata: labels: service: site spec: containers: - name: aspnetapp image: mcr.microsoft.com/dotnet/core/samples:aspnetapp imagePullPolicy: IfNotPresent ports: - containerPort: 80 readinessProbe: httpGet: path: / port: 80 periodSeconds: 3 timeoutSeconds: 1 Kubernetes API Reference: * Container Probes * HttpGet Action Note: readinessProbe and livenessProbe are supported when configured with httpGet . Probing on a port other than the one exposed on the pod is currently not supported. HttpHeaders , InitialDelaySeconds , SuccessThreshold are not supported. Without readinessProbe or livenessProbe If the above probes are not provided, then Ingress Controller make an assumption that the service is reachable on Path specified for backend-path-prefix annotation or the path specified in the ingress definition for the service. Default Values for Health Probe For any property that can not be inferred by the readiness/liveness probe, Default values are set. Application Gateway Probe Property Default Value Path / Host localhost Protocol HTTP Timeout 30 Interval 30 UnhealthyThreshold 3","title":"Probes"},{"location":"features/probes/#adding-health-probes-to-your-service","text":"By default, Ingress controller will provision an HTTP GET probe for the exposed pods. The probe properties can be customized by adding a Readiness or Liveness Probe to your deployment / pod spec.","title":"Adding Health Probes to your service"},{"location":"features/probes/#with-readinessprobe-or-livenessprobe","text":"apiVersion: extensions/v1beta1 kind: Deployment metadata: name: aspnetapp spec: replicas: 3 template: metadata: labels: service: site spec: containers: - name: aspnetapp image: mcr.microsoft.com/dotnet/core/samples:aspnetapp imagePullPolicy: IfNotPresent ports: - containerPort: 80 readinessProbe: httpGet: path: / port: 80 periodSeconds: 3 timeoutSeconds: 1 Kubernetes API Reference: * Container Probes * HttpGet Action Note: readinessProbe and livenessProbe are supported when configured with httpGet . Probing on a port other than the one exposed on the pod is currently not supported. HttpHeaders , InitialDelaySeconds , SuccessThreshold are not supported.","title":"With readinessProbe or livenessProbe"},{"location":"features/probes/#without-readinessprobe-or-livenessprobe","text":"If the above probes are not provided, then Ingress Controller make an assumption that the service is reachable on Path specified for backend-path-prefix annotation or the path specified in the ingress definition for the service.","title":"Without readinessProbe or livenessProbe"},{"location":"features/probes/#default-values-for-health-probe","text":"For any property that can not be inferred by the readiness/liveness probe, Default values are set. Application Gateway Probe Property Default Value Path / Host localhost Protocol HTTP Timeout 30 Interval 30 UnhealthyThreshold 3","title":"Default Values for Health Probe"},{"location":"how-tos/helm-upgrade/","text":"Upgrading AGIC using Helm The Azure Application Gateway Ingress Controller for Kubernetes (AGIC) can be upgraded using a Helm repository hosted on GitHub . Before we begin the upgrade procedure, ensure that you have added the required repository: View your currently added Helm repositories with: helm repo list Add the AGIC repo with: helm repo add \\ application-gateway-kubernetes-ingress \\ https://azure.github.io/application-gateway-kubernetes-ingress/helm/ Upgrade Refresh the AGIC Helm repository to get the latest release: helm repo update View available versions of the application-gateway-kubernetes-ingress chart: helm search -l application-gateway-kubernetes-ingress Sample response: NAME CHART VERSION APP VERSION DESCRIPTION application-gateway-kubernetes-ingress/ingress-azure 0.7.0-rc1 0.7.0-rc1 Use Azure Application Gateway as the ingress for an Azure... application-gateway-kubernetes-ingress/ingress-azure 0.6.0 0.6.0 Use Azure Application Gateway as the ingress for an Azure... Latest available version from the list above is: 0.7.0-rc1 View the Helm charts currently installed: helm list Sample response: NAME REVISION UPDATED STATUS CHART APP VERSION NAMESPACE odd-billygoat 22 Fri Jun 21 15:56:06 2019 FAILED ingress-azure-0.7.0-rc1 0.7.0-rc1 default The Helm chart installation from the sample response above is named odd-billygoat . We will use this name for the rest of the commands. Your actual deployment name will most likely differ. Upgrade the Helm deployment to a new version: helm upgrade \\ odd-billygoat \\ application-gateway-kubernetes-ingress/ingress-azure \\ --version 0.7.0-rc1 Rollback Should the Helm deployment fail, you can rollback to a previous release. Get the last known healthy release number: helm history odd-billygoat Sample output: REVISION UPDATED STATUS CHART DESCRIPTION 1 Mon Jun 17 13:49:42 2019 DEPLOYED ingress-azure-0.6.0 Install complete 2 Fri Jun 21 15:56:06 2019 FAILED ingress-azure-xx xxxx From the sample output of the helm history command it looks like the last successful deployment of our odd-billygoat was revision 1 Rollback to the last successful revision: helm rollback odd-billygoat 1","title":"Upgrading AGIC using Helm"},{"location":"how-tos/helm-upgrade/#upgrading-agic-using-helm","text":"The Azure Application Gateway Ingress Controller for Kubernetes (AGIC) can be upgraded using a Helm repository hosted on GitHub . Before we begin the upgrade procedure, ensure that you have added the required repository: View your currently added Helm repositories with: helm repo list Add the AGIC repo with: helm repo add \\ application-gateway-kubernetes-ingress \\ https://azure.github.io/application-gateway-kubernetes-ingress/helm/","title":"Upgrading AGIC using Helm"},{"location":"how-tos/helm-upgrade/#upgrade","text":"Refresh the AGIC Helm repository to get the latest release: helm repo update View available versions of the application-gateway-kubernetes-ingress chart: helm search -l application-gateway-kubernetes-ingress Sample response: NAME CHART VERSION APP VERSION DESCRIPTION application-gateway-kubernetes-ingress/ingress-azure 0.7.0-rc1 0.7.0-rc1 Use Azure Application Gateway as the ingress for an Azure... application-gateway-kubernetes-ingress/ingress-azure 0.6.0 0.6.0 Use Azure Application Gateway as the ingress for an Azure... Latest available version from the list above is: 0.7.0-rc1 View the Helm charts currently installed: helm list Sample response: NAME REVISION UPDATED STATUS CHART APP VERSION NAMESPACE odd-billygoat 22 Fri Jun 21 15:56:06 2019 FAILED ingress-azure-0.7.0-rc1 0.7.0-rc1 default The Helm chart installation from the sample response above is named odd-billygoat . We will use this name for the rest of the commands. Your actual deployment name will most likely differ. Upgrade the Helm deployment to a new version: helm upgrade \\ odd-billygoat \\ application-gateway-kubernetes-ingress/ingress-azure \\ --version 0.7.0-rc1","title":"Upgrade"},{"location":"how-tos/helm-upgrade/#rollback","text":"Should the Helm deployment fail, you can rollback to a previous release. Get the last known healthy release number: helm history odd-billygoat Sample output: REVISION UPDATED STATUS CHART DESCRIPTION 1 Mon Jun 17 13:49:42 2019 DEPLOYED ingress-azure-0.6.0 Install complete 2 Fri Jun 21 15:56:06 2019 FAILED ingress-azure-xx xxxx From the sample output of the helm history command it looks like the last successful deployment of our odd-billygoat was revision 1 Rollback to the last successful revision: helm rollback odd-billygoat 1","title":"Rollback"},{"location":"how-tos/lets-encrypt/","text":"Certificate issuance with LetsEncrypt.org This section configures your AKS to leverage LetsEncrypt.org and automatically obtain a TLS/SSL certificate for your domain. The certificate will be installed on Application Gateway, which will perform SSL/TLS termination for your AKS cluster. The setup described here uses the cert-manager Kubernetes add-on, which automates the creation and management of certificates. Follow the steps below to install cert-manager on your existing AKS cluster. Helm Chart Run the following script to install the cert-manager helm chart. This will: create a new cert-manager namespace on your AKS create the following CRDs: Certificate, Challenge, ClusterIssuer, Issuer, Order install cert-manager chart (from docs.cert-manager.io) #!/bin/bash # Install the CustomResourceDefinition resources separately kubectl apply -f https://raw.githubusercontent.com/jetstack/cert-manager/release-0.8/deploy/manifests/00-crds.yaml # Create the namespace for cert-manager kubectl create namespace cert-manager # Label the cert-manager namespace to disable resource validation kubectl label namespace cert-manager certmanager.k8s.io/disable-validation=true # Add the Jetstack Helm repository helm repo add jetstack https://charts.jetstack.io # Update your local Helm chart repository cache helm repo update # Install the cert-manager Helm chart helm install \\ --name cert-manager \\ --namespace cert-manager \\ --version v0.8.0 \\ jetstack/cert-manager ClusterIssuer Resource Create a ClusterIssuer resource. It is required by cert-manager to represent the Lets Encrypt certificate authority where the signed certificates will be obtained. By using the non-namespaced ClusterIssuer resource, cert-manager will issue certificates that can be consumed from multiple namespaces. Let\u2019s Encrypt uses the ACME protocol to verify that you control a given domain name and to issue you a certificate. More details on configuring ClusterIssuer properties here . ClusterIssuer will instruct cert-manager to issue certificates using the Lets Encrypt staging environment used for testing (the root certificate not present in browser/client trust stores). The default challenge type in the YAML below is http01 . Other challenges are documented on letsencrypt.org - Challenge Types IMPORTANT: Update <YOUR.EMAIL@ADDRESS> in the YAML below #!/bin/bash kubectl apply -f - <<EOF apiVersion: certmanager.k8s.io/v1alpha1 kind: ClusterIssuer metadata: name: letsencrypt-staging spec: acme: # You must replace this email address with your own. # Let's Encrypt will use this to contact you about expiring # certificates, and issues related to your account. email: <YOUR.EMAIL@ADDRESS> # ACME server URL for Let\u2019s Encrypt\u2019s staging environment. # The staging environment will not issue trusted certificates but is # used to ensure that the verification process is working properly # before moving to production server: https://acme-staging-v02.api.letsencrypt.org/directory privateKeySecretRef: # Secret resource used to store the account's private key. name: example-issuer-account-key # Enable the HTTP-01 challenge provider # you prove ownership of a domain by ensuring that a particular # file is present at the domain http01: {} EOF Deploy App Create an Ingress resource to Expose the guestbook application using the Application Gateway with the Lets Encrypt Certificate. Ensure you Application Gateway has a public Frontend IP configuration with a DNS name (either using the default azure.com domain, or provision a Azure DNS Zone service, and assign your own custom domain). Note the annotation certmanager.k8s.io/cluster-issuer: letsencrypt-staging , which tells cert-manager to process the tagged Ingress resource. IMPORTANT: Update <PLACEHOLDERS.COM> in the YAML below with your own domain (or the Application Gateway one, for example 'kh-aks-ingress.westeurope.cloudapp.azure.com') kubectl apply -f - <<EOF apiVersion: extensions/v1beta1 kind: Ingress metadata: name: guestbook-letsencrypt-staging annotations: kubernetes.io/ingress.class: azure/application-gateway certmanager.k8s.io/cluster-issuer: letsencrypt-staging spec: tls: - hosts: - <PLACEHOLDERS.COM> secretName: guestbook-secret-name rules: - host: <PLACEHOLDERS.COM> http: paths: - backend: serviceName: frontend servicePort: 80 EOF After a few seconds, you can access the guestbook service through the Application Gateway HTTPS url using the automatically issued staging Lets Encrypt certificate. Your browser may warn you of an invalid cert authority. The staging certificate is issued by CN=Fake LE Intermediate X1 . This is an indication that the system worked as expected and you are ready for your production certificate. Production Certificate Once your staging certificate is setup successfully you can switch to a production ACME server: Replace the staging annotation on your Ingress resource with: certmanager.k8s.io/cluster-issuer: letsencrypt-prod Delete the existing staging ClusterIssuer you created in the previous step and create a new one by replacing the ACME server from the ClusterIssuer YAML above with https://acme-v02.api.letsencrypt.org/directory Certificate Expiration and Renewal Before the Lets Encrypt certificate expires, cert-manager will automatically update the certificate in the Kubernetes secret store. At that point, Application Gateway Ingress Controller will apply the updated secret referenced in the ingress resources it is using to configure the Application Gateway.","title":"Certificate issuance with LetsEncrypt.org"},{"location":"how-tos/lets-encrypt/#certificate-issuance-with-letsencryptorg","text":"This section configures your AKS to leverage LetsEncrypt.org and automatically obtain a TLS/SSL certificate for your domain. The certificate will be installed on Application Gateway, which will perform SSL/TLS termination for your AKS cluster. The setup described here uses the cert-manager Kubernetes add-on, which automates the creation and management of certificates. Follow the steps below to install cert-manager on your existing AKS cluster. Helm Chart Run the following script to install the cert-manager helm chart. This will: create a new cert-manager namespace on your AKS create the following CRDs: Certificate, Challenge, ClusterIssuer, Issuer, Order install cert-manager chart (from docs.cert-manager.io) #!/bin/bash # Install the CustomResourceDefinition resources separately kubectl apply -f https://raw.githubusercontent.com/jetstack/cert-manager/release-0.8/deploy/manifests/00-crds.yaml # Create the namespace for cert-manager kubectl create namespace cert-manager # Label the cert-manager namespace to disable resource validation kubectl label namespace cert-manager certmanager.k8s.io/disable-validation=true # Add the Jetstack Helm repository helm repo add jetstack https://charts.jetstack.io # Update your local Helm chart repository cache helm repo update # Install the cert-manager Helm chart helm install \\ --name cert-manager \\ --namespace cert-manager \\ --version v0.8.0 \\ jetstack/cert-manager ClusterIssuer Resource Create a ClusterIssuer resource. It is required by cert-manager to represent the Lets Encrypt certificate authority where the signed certificates will be obtained. By using the non-namespaced ClusterIssuer resource, cert-manager will issue certificates that can be consumed from multiple namespaces. Let\u2019s Encrypt uses the ACME protocol to verify that you control a given domain name and to issue you a certificate. More details on configuring ClusterIssuer properties here . ClusterIssuer will instruct cert-manager to issue certificates using the Lets Encrypt staging environment used for testing (the root certificate not present in browser/client trust stores). The default challenge type in the YAML below is http01 . Other challenges are documented on letsencrypt.org - Challenge Types IMPORTANT: Update <YOUR.EMAIL@ADDRESS> in the YAML below #!/bin/bash kubectl apply -f - <<EOF apiVersion: certmanager.k8s.io/v1alpha1 kind: ClusterIssuer metadata: name: letsencrypt-staging spec: acme: # You must replace this email address with your own. # Let's Encrypt will use this to contact you about expiring # certificates, and issues related to your account. email: <YOUR.EMAIL@ADDRESS> # ACME server URL for Let\u2019s Encrypt\u2019s staging environment. # The staging environment will not issue trusted certificates but is # used to ensure that the verification process is working properly # before moving to production server: https://acme-staging-v02.api.letsencrypt.org/directory privateKeySecretRef: # Secret resource used to store the account's private key. name: example-issuer-account-key # Enable the HTTP-01 challenge provider # you prove ownership of a domain by ensuring that a particular # file is present at the domain http01: {} EOF Deploy App Create an Ingress resource to Expose the guestbook application using the Application Gateway with the Lets Encrypt Certificate. Ensure you Application Gateway has a public Frontend IP configuration with a DNS name (either using the default azure.com domain, or provision a Azure DNS Zone service, and assign your own custom domain). Note the annotation certmanager.k8s.io/cluster-issuer: letsencrypt-staging , which tells cert-manager to process the tagged Ingress resource. IMPORTANT: Update <PLACEHOLDERS.COM> in the YAML below with your own domain (or the Application Gateway one, for example 'kh-aks-ingress.westeurope.cloudapp.azure.com') kubectl apply -f - <<EOF apiVersion: extensions/v1beta1 kind: Ingress metadata: name: guestbook-letsencrypt-staging annotations: kubernetes.io/ingress.class: azure/application-gateway certmanager.k8s.io/cluster-issuer: letsencrypt-staging spec: tls: - hosts: - <PLACEHOLDERS.COM> secretName: guestbook-secret-name rules: - host: <PLACEHOLDERS.COM> http: paths: - backend: serviceName: frontend servicePort: 80 EOF After a few seconds, you can access the guestbook service through the Application Gateway HTTPS url using the automatically issued staging Lets Encrypt certificate. Your browser may warn you of an invalid cert authority. The staging certificate is issued by CN=Fake LE Intermediate X1 . This is an indication that the system worked as expected and you are ready for your production certificate. Production Certificate Once your staging certificate is setup successfully you can switch to a production ACME server: Replace the staging annotation on your Ingress resource with: certmanager.k8s.io/cluster-issuer: letsencrypt-prod Delete the existing staging ClusterIssuer you created in the previous step and create a new one by replacing the ACME server from the ClusterIssuer YAML above with https://acme-v02.api.letsencrypt.org/directory Certificate Expiration and Renewal Before the Lets Encrypt certificate expires, cert-manager will automatically update the certificate in the Kubernetes secret store. At that point, Application Gateway Ingress Controller will apply the updated secret referenced in the ingress resources it is using to configure the Application Gateway.","title":"Certificate issuance with LetsEncrypt.org"},{"location":"how-tos/websockets/","text":"Expose a WebSocket server As outlined in the Application Gateway v2 documentation - it provides native support for the WebSocket and HTTP/2 protocols . Please note, that for both Application Gateway and the Kubernetes Ingress - there is no user-configurable setting to selectively enable or disable WebSocket support. The Kubernetes deployment YAML below shows the minimum configuration used to deploy a WebSocket server, which is the same as deploying a regular web server: apiVersion: apps/v1 kind: Deployment metadata: name: websocket-server spec: selector: matchLabels: app: ws-app replicas: 2 template: metadata: labels: app: ws-app spec: containers: - name: websocket-app imagePullPolicy: Always image: your-container-repo.azurecr.io/websockets-app ports: - containerPort: 8888 imagePullSecrets: - name: azure-container-registry-credentials --- apiVersion: v1 kind: Service metadata: name: websocket-app-service spec: selector: app: ws-app ports: - protocol: TCP port: 80 targetPort: 8888 --- apiVersion: extensions/v1beta1 kind: Ingress metadata: name: websocket-repeater annotations: kubernetes.io/ingress.class: azure/application-gateway spec: rules: - host: ws.contoso.com http: paths: - backend: serviceName: websocket-app-service servicePort: 80 Given that all the prerequisites are fulfilled, and you have an App Gateway controlled by a K8s Ingress in your AKS, the deployment above would result in a WebSockets server exposed on port 80 of your App Gateway's public IP and the ws.contoso.com domain. The following cURL command would test the WebSocket server deployment: curl -i -N -H \"Connection: Upgrade\" \\ -H \"Upgrade: websocket\" \\ -H \"Origin: http://localhost\" \\ -H \"Host: ws.contoso.com\" \\ -H \"Sec-Websocket-Version: 13\" \\ -H \"Sec-WebSocket-Key: 123\" \\ http://1.2.3.4:80/ws WebSocket Health Probes If your deployment does not explicitly define health probes, App Gateway would attempt an HTTP GET on your WebSocket server endpoint. Depending on the server implementation ( here is one we love ) WebSocket specific headers may be required ( Sec-Websocket-Version for instance). Since App Gateway does not add WebSocket headers, the App Gateway's health probe response from your WebSocket server will most likely be 400 Bad Request . As a result App Gateway will mark your pods as unhealthy, which will eventually result in a 502 Bad Gateway for the consumers of the WebSocket server. To avoid this you may need to add an HTTP GET handler for a health check to your server ( /health for instance, which returns 200 OK ).","title":"Websockets"},{"location":"how-tos/websockets/#expose-a-websocket-server","text":"As outlined in the Application Gateway v2 documentation - it provides native support for the WebSocket and HTTP/2 protocols . Please note, that for both Application Gateway and the Kubernetes Ingress - there is no user-configurable setting to selectively enable or disable WebSocket support. The Kubernetes deployment YAML below shows the minimum configuration used to deploy a WebSocket server, which is the same as deploying a regular web server: apiVersion: apps/v1 kind: Deployment metadata: name: websocket-server spec: selector: matchLabels: app: ws-app replicas: 2 template: metadata: labels: app: ws-app spec: containers: - name: websocket-app imagePullPolicy: Always image: your-container-repo.azurecr.io/websockets-app ports: - containerPort: 8888 imagePullSecrets: - name: azure-container-registry-credentials --- apiVersion: v1 kind: Service metadata: name: websocket-app-service spec: selector: app: ws-app ports: - protocol: TCP port: 80 targetPort: 8888 --- apiVersion: extensions/v1beta1 kind: Ingress metadata: name: websocket-repeater annotations: kubernetes.io/ingress.class: azure/application-gateway spec: rules: - host: ws.contoso.com http: paths: - backend: serviceName: websocket-app-service servicePort: 80 Given that all the prerequisites are fulfilled, and you have an App Gateway controlled by a K8s Ingress in your AKS, the deployment above would result in a WebSockets server exposed on port 80 of your App Gateway's public IP and the ws.contoso.com domain. The following cURL command would test the WebSocket server deployment: curl -i -N -H \"Connection: Upgrade\" \\ -H \"Upgrade: websocket\" \\ -H \"Origin: http://localhost\" \\ -H \"Host: ws.contoso.com\" \\ -H \"Sec-Websocket-Version: 13\" \\ -H \"Sec-WebSocket-Key: 123\" \\ http://1.2.3.4:80/ws","title":"Expose a WebSocket server"},{"location":"how-tos/websockets/#websocket-health-probes","text":"If your deployment does not explicitly define health probes, App Gateway would attempt an HTTP GET on your WebSocket server endpoint. Depending on the server implementation ( here is one we love ) WebSocket specific headers may be required ( Sec-Websocket-Version for instance). Since App Gateway does not add WebSocket headers, the App Gateway's health probe response from your WebSocket server will most likely be 400 Bad Request . As a result App Gateway will mark your pods as unhealthy, which will eventually result in a 502 Bad Gateway for the consumers of the WebSocket server. To avoid this you may need to add an HTTP GET handler for a health check to your server ( /health for instance, which returns 200 OK ).","title":"WebSocket Health Probes"},{"location":"setup/install-existing/","text":"Brownfield Deployment Table of Contents Prerequisites Setting up Authentication with Azure Resource Manager (ARM) Setting up aad-pod-identity - Create Azure Identity on ARM Install Ingress Controller using Helm Setting up Application Gateway ingress controller on AKS The Application Gateway Ingress controller runs as pod within the AKS cluster. It listens to Kubernetes Ingress Resources from the Kubernetes API server and converts them to Azure Application Gateway configuration and updates the Application Gateway through the Azure Resource Manager (ARM). In order to install the ingress controller on AKS we use Helm . Prerequisites An existing Azure Application Gateway v2 . An existing Azure Kubernetes Service cluster with Advanced Networking enabled. The aad-pod-identity service is installed on the AKS cluster. Setting up Authentication with Azure Resource Manager Since the ingress controller needs to talk to the Kubernetes API server and the Azure Resource Manager it will need an identity to access both these entities. Since we are currently supporting only a non-RBAC cluster, the ingress controller currently does not need an identity to talk to the Kubernetes API server but needs and identity to talk to ARM. Setting up aad-pod-identity The aad-pod-identity gives a clean way of exposing an existing Azure AD identity to a pod. Kindly follow the aad-pod-identity installation instructions to deploy the aad-pod-identity service on your AKS cluster. This is a pre-requisite for installing the ingress controller. Create Azure Identity on ARM Create an Azure identity in the same resource group as the AKS nodes (typically the resource group with a MC_ prefix string) az identity create -g <resourcegroup> -n <identity-name> Find the principal, resource and client ID for this identity az identity show -g <resourcegroup> -n <identity-name> Assign this new identity Contributor access on the application gateway az role assignment create --role Contributor --assignee <principal ID from the command above> --scope <Resource ID of Application Gateway> Assign this new identity Reader access on the resource group that the application gateway belongs to az role assignment create --role Reader --assignee <principal ID from the command above> --scope <Resource ID of Application Gateway Resource Group> Install Ingress Controller as a Helm Chart Add the application-gateway-kubernetes-ingress helm repo and perform a helm update helm repo add application-gateway-kubernetes-ingress https://azure.github.io/application-gateway-kubernetes-ingress/helm/ helm repo update Edit helm-config.yaml and fill in the values for appgw and armAuth # This file contains the essential configs for the ingress controller helm chart # Verbosity level of the App Gateway Ingress Controller verbosityLevel: 3 ################################################################################ # Specify which application gateway the ingress controller will manage # appgw: subscriptionId: <subscription-id> resourceGroup: <resourcegroup-name> name: <applicationgateway-name> ################################################################################ # Specify which kubernetes namespace the ingress controller will watch # Default value is \"default\" # Leaving this variable out or setting it to blank or empty string would # result in Ingress Controller observing all acessible namespaces. # # kubernetes: # watchNamespace: <namespace> ################################################################################ # Specify the authentication with Azure Resource Manager # # Two authentication methods are available: # - Option 1: AAD-Pod-Identity (https://github.com/Azure/aad-pod-identity) armAuth: type: aadPodIdentity identityResourceID: <identity-resource-id> identityClientID: <identity-client-id> ################################################################################ # Specify if the cluster is RBAC enabled or not rbac: enabled: false # true/false ################################################################################ # Specify aks cluster related information. THIS IS BEING DEPRECATED. aksClusterConfiguration: apiServerAddress: <aks-api-server-address> NOTE: The <identity-resource-id> and <identity-client-id> are the properties of the Azure AD Identity you setup in the previous section. You can retrieve this information by running the following command: az identity show -g <resourcegroup> -n <identity-name> Where <resourcegroup> is the resource group in which AKS cluster is running (this would have the prefix MC_ ). Install the helm chart application-gateway-kubernetes-ingress with the helm-config.yaml configuration from the previous step helm install -f <helm-config.yaml> application-gateway-kubernetes-ingress/ingress-azure Check the log of the newly created pod to verify if it started properly Refer to the tutorials to understand how you can expose an AKS service over HTTP or HTTPS, to the internet, using an Azure Application Gateway.","title":"Brownfield Deployment"},{"location":"setup/install-existing/#brownfield-deployment","text":"","title":"Brownfield Deployment"},{"location":"setup/install-existing/#table-of-contents","text":"Prerequisites Setting up Authentication with Azure Resource Manager (ARM) Setting up aad-pod-identity - Create Azure Identity on ARM Install Ingress Controller using Helm","title":"Table of Contents"},{"location":"setup/install-existing/#setting-up-application-gateway-ingress-controller-on-aks","text":"The Application Gateway Ingress controller runs as pod within the AKS cluster. It listens to Kubernetes Ingress Resources from the Kubernetes API server and converts them to Azure Application Gateway configuration and updates the Application Gateway through the Azure Resource Manager (ARM). In order to install the ingress controller on AKS we use Helm .","title":"Setting up Application Gateway ingress controller on AKS"},{"location":"setup/install-existing/#prerequisites","text":"An existing Azure Application Gateway v2 . An existing Azure Kubernetes Service cluster with Advanced Networking enabled. The aad-pod-identity service is installed on the AKS cluster.","title":"Prerequisites"},{"location":"setup/install-existing/#setting-up-authentication-with-azure-resource-manager","text":"Since the ingress controller needs to talk to the Kubernetes API server and the Azure Resource Manager it will need an identity to access both these entities. Since we are currently supporting only a non-RBAC cluster, the ingress controller currently does not need an identity to talk to the Kubernetes API server but needs and identity to talk to ARM.","title":"Setting up Authentication with Azure Resource Manager"},{"location":"setup/install-existing/#setting-up-aad-pod-identity","text":"The aad-pod-identity gives a clean way of exposing an existing Azure AD identity to a pod. Kindly follow the aad-pod-identity installation instructions to deploy the aad-pod-identity service on your AKS cluster. This is a pre-requisite for installing the ingress controller.","title":"Setting up aad-pod-identity"},{"location":"setup/install-existing/#create-azure-identity-on-arm","text":"Create an Azure identity in the same resource group as the AKS nodes (typically the resource group with a MC_ prefix string) az identity create -g <resourcegroup> -n <identity-name> Find the principal, resource and client ID for this identity az identity show -g <resourcegroup> -n <identity-name> Assign this new identity Contributor access on the application gateway az role assignment create --role Contributor --assignee <principal ID from the command above> --scope <Resource ID of Application Gateway> Assign this new identity Reader access on the resource group that the application gateway belongs to az role assignment create --role Reader --assignee <principal ID from the command above> --scope <Resource ID of Application Gateway Resource Group>","title":"Create Azure Identity on ARM"},{"location":"setup/install-existing/#install-ingress-controller-as-a-helm-chart","text":"Add the application-gateway-kubernetes-ingress helm repo and perform a helm update helm repo add application-gateway-kubernetes-ingress https://azure.github.io/application-gateway-kubernetes-ingress/helm/ helm repo update Edit helm-config.yaml and fill in the values for appgw and armAuth # This file contains the essential configs for the ingress controller helm chart # Verbosity level of the App Gateway Ingress Controller verbosityLevel: 3 ################################################################################ # Specify which application gateway the ingress controller will manage # appgw: subscriptionId: <subscription-id> resourceGroup: <resourcegroup-name> name: <applicationgateway-name> ################################################################################ # Specify which kubernetes namespace the ingress controller will watch # Default value is \"default\" # Leaving this variable out or setting it to blank or empty string would # result in Ingress Controller observing all acessible namespaces. # # kubernetes: # watchNamespace: <namespace> ################################################################################ # Specify the authentication with Azure Resource Manager # # Two authentication methods are available: # - Option 1: AAD-Pod-Identity (https://github.com/Azure/aad-pod-identity) armAuth: type: aadPodIdentity identityResourceID: <identity-resource-id> identityClientID: <identity-client-id> ################################################################################ # Specify if the cluster is RBAC enabled or not rbac: enabled: false # true/false ################################################################################ # Specify aks cluster related information. THIS IS BEING DEPRECATED. aksClusterConfiguration: apiServerAddress: <aks-api-server-address> NOTE: The <identity-resource-id> and <identity-client-id> are the properties of the Azure AD Identity you setup in the previous section. You can retrieve this information by running the following command: az identity show -g <resourcegroup> -n <identity-name> Where <resourcegroup> is the resource group in which AKS cluster is running (this would have the prefix MC_ ). Install the helm chart application-gateway-kubernetes-ingress with the helm-config.yaml configuration from the previous step helm install -f <helm-config.yaml> application-gateway-kubernetes-ingress/ingress-azure Check the log of the newly created pod to verify if it started properly Refer to the tutorials to understand how you can expose an AKS service over HTTP or HTTPS, to the internet, using an Azure Application Gateway.","title":"Install Ingress Controller as a Helm Chart"},{"location":"setup/install-new/","text":"Greenfield Deployment Table of Contents Deploying the infrastructure on Azure Setting up Application Gateway Ingress Controller on AKS Deploying the infrastructure on Azure To create the pre-requisite Azure resources, you can use the following template. It creates: Azure Virtual Network with 2 subnets. Azure Application Gateway v2. Azure Kubernetes Service cluster with required permission to deploy nodes in the Virtual Network. You have an option to deploy RBAC enabled AKS cluster User Assigned Identity to initialize the aad-pod-identity service and ingress controller. Set required RBACs. Prerequisites The steps below require the following software to be installed on your workstation: az - Azure CLI: installation instructions kubectl - Kubernetes command-line tool: installation instructions helm - tool for managing pre-configured Kubernetes resources: installation instructions Steps Create an Azure Active Directory (Azure AD) service principal object. This object will be assigned to the AKS cluster in the template. As a result of executing the commands below you will have an appId , password , and objectId values. Execute the following commands: az ad sp create-for-rbac --skip-assignment - creates an AD service principal object. Record and securely store the values for the appId and password keys from the JSON output of this command. ( Read more about RBAC ) az ad sp show --id <appId> --query \"objectId\" - retrieves the objectId of the newly created service principal. Replace <appId> with the value for the appId key from the JSON output of the previous command. Record the objectId value returned. After creating the service principal in the step above, click to create a custom template deployment. Provide the appId for servicePrincipalClientId, password and objectId in the parameters. Note: For deploying an RBAC enabled cluster, set aksEnabledRBAC parameter to true . The templated deployment will create: - Managed Identity - Virtual Network - Public IP Address - Application Gateway - Azure Kubernetes Service After the deployment completes, you will find the parameters needed for the steps below in the deployment outputs window. (Navigate to the deployment's output by following this path in the Azure portal : Home \ud83e\udc06 *resource group* \ud83e\udc06 Deployments \ud83e\udc06 *new deployment* \ud83e\udc06 Outputs ) Example: Setting up Application Gateway Ingress Controller on AKS Overview With the instructions in the previous section we created and configured a new Azure Kubernetes Service (AKS) cluster. We are now ready to deploy to our new Kubernetes infrastructure. The instructions below will guide us through the proccess of installing the following 2 components on our new AKS: Azure Active Directory Pod Identity - Provides token-based access to the Azure Resource Manager (ARM) via user-assigned identity. Adding this system will result in the installation of the following within your AKS cluster: Custom Kubernetes resource definitions: AzureIdentity , AzureAssignedIdentity , AzureIdentityBinding Managed Identity Controller (MIC) component Node Managed Identity (NMI) component Application Gateway Ingress Controller - This is the controller which monitors ingress-related events and actively keeps your Azure Application Gateway installation in sync with the changes within the AKS cluster. Steps: To configure kubectl to connect to the deployed Azure Kubernetes Cluster, follow these instructions . Add aad pod identity service to the cluster using the following command. This service will be used by the ingress controller. You can refer aad-pod-identity for more information. RBAC disabled AKS cluster kubectl create -f https://raw.githubusercontent.com/Azure/aad-pod-identity/master/deploy/infra/deployment.yaml RBAC enabled AKS cluster kubectl create -f https://raw.githubusercontent.com/Azure/aad-pod-identity/master/deploy/infra/deployment-rbac.yaml Install Helm and run the following to add application-gateway-kubernetes-ingress helm package: RBAC disabled AKS cluster helm init helm repo add application-gateway-kubernetes-ingress https://azure.github.io/application-gateway-kubernetes-ingress/helm/ helm repo update RBAC enabled AKS cluster kubectl create serviceaccount --namespace kube-system tiller-sa kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller-sa helm init --tiller-namespace kube-system --service-account tiller-sa helm repo add application-gateway-kubernetes-ingress https://azure.github.io/application-gateway-kubernetes-ingress/helm/ helm repo update Edit helm-config.yaml and fill in the values for appgw and armAuth # This file contains the essential configs for the ingress controller helm chart # Verbosity level of the App Gateway Ingress Controller verbosityLevel: 3 ################################################################################ # Specify which application gateway the ingress controller will manage # appgw: subscriptionId: <subscription-id> resourceGroup: <resourcegroup-name> name: <applicationgateway-name> ################################################################################ # Specify which kubernetes namespace the ingress controller will watch # Default value is \"default\" # Leaving this variable out or setting it to blank or empty string would # result in Ingress Controller observing all acessible namespaces. # # kubernetes: # watchNamespace: <namespace> ################################################################################ # Specify the authentication with Azure Resource Manager # # Two authentication methods are available: # - Option 1: AAD-Pod-Identity (https://github.com/Azure/aad-pod-identity) armAuth: type: aadPodIdentity identityResourceID: <identity-resource-id> identityClientID: <identity-client-id> ################################################################################ # Specify if the cluster is RBAC enabled or not rbac: enabled: false # true/false ################################################################################ # Specify aks cluster related information. THIS IS BEING DEPRECATED. aksClusterConfiguration: apiServerAddress: <aks-api-server-address> NOTE: The <identity-resource-id> and <identity-client-id> are the properties of the Azure AD Identity you setup in the previous section. You can retrieve this information by running the following command: az identity show -g <resourcegroup> -n <identity-name> Where <resourcegroup> is the resource group in which the top level AKS cluster object, Application Gateway and Managed Identify are deployed. Then execute the following to the install the Application Gateway ingress controller package. helm install -f helm-config.yaml application-gateway-kubernetes-ingress/ingress-azure Jump next to tutorials to understand how you can expose an AKS service over HTTP or HTTPS, to the internet, using an Azure Application Gateway.","title":"Greenfield Deployment"},{"location":"setup/install-new/#greenfield-deployment","text":"","title":"Greenfield Deployment"},{"location":"setup/install-new/#table-of-contents","text":"Deploying the infrastructure on Azure Setting up Application Gateway Ingress Controller on AKS","title":"Table of Contents"},{"location":"setup/install-new/#deploying-the-infrastructure-on-azure","text":"To create the pre-requisite Azure resources, you can use the following template. It creates: Azure Virtual Network with 2 subnets. Azure Application Gateway v2. Azure Kubernetes Service cluster with required permission to deploy nodes in the Virtual Network. You have an option to deploy RBAC enabled AKS cluster User Assigned Identity to initialize the aad-pod-identity service and ingress controller. Set required RBACs.","title":"Deploying the infrastructure on Azure"},{"location":"setup/install-new/#prerequisites","text":"The steps below require the following software to be installed on your workstation: az - Azure CLI: installation instructions kubectl - Kubernetes command-line tool: installation instructions helm - tool for managing pre-configured Kubernetes resources: installation instructions","title":"Prerequisites"},{"location":"setup/install-new/#steps","text":"Create an Azure Active Directory (Azure AD) service principal object. This object will be assigned to the AKS cluster in the template. As a result of executing the commands below you will have an appId , password , and objectId values. Execute the following commands: az ad sp create-for-rbac --skip-assignment - creates an AD service principal object. Record and securely store the values for the appId and password keys from the JSON output of this command. ( Read more about RBAC ) az ad sp show --id <appId> --query \"objectId\" - retrieves the objectId of the newly created service principal. Replace <appId> with the value for the appId key from the JSON output of the previous command. Record the objectId value returned. After creating the service principal in the step above, click to create a custom template deployment. Provide the appId for servicePrincipalClientId, password and objectId in the parameters. Note: For deploying an RBAC enabled cluster, set aksEnabledRBAC parameter to true . The templated deployment will create: - Managed Identity - Virtual Network - Public IP Address - Application Gateway - Azure Kubernetes Service After the deployment completes, you will find the parameters needed for the steps below in the deployment outputs window. (Navigate to the deployment's output by following this path in the Azure portal : Home \ud83e\udc06 *resource group* \ud83e\udc06 Deployments \ud83e\udc06 *new deployment* \ud83e\udc06 Outputs ) Example:","title":"Steps"},{"location":"setup/install-new/#setting-up-application-gateway-ingress-controller-on-aks","text":"","title":"Setting up Application Gateway Ingress Controller on AKS"},{"location":"setup/install-new/#overview","text":"With the instructions in the previous section we created and configured a new Azure Kubernetes Service (AKS) cluster. We are now ready to deploy to our new Kubernetes infrastructure. The instructions below will guide us through the proccess of installing the following 2 components on our new AKS: Azure Active Directory Pod Identity - Provides token-based access to the Azure Resource Manager (ARM) via user-assigned identity. Adding this system will result in the installation of the following within your AKS cluster: Custom Kubernetes resource definitions: AzureIdentity , AzureAssignedIdentity , AzureIdentityBinding Managed Identity Controller (MIC) component Node Managed Identity (NMI) component Application Gateway Ingress Controller - This is the controller which monitors ingress-related events and actively keeps your Azure Application Gateway installation in sync with the changes within the AKS cluster. Steps: To configure kubectl to connect to the deployed Azure Kubernetes Cluster, follow these instructions . Add aad pod identity service to the cluster using the following command. This service will be used by the ingress controller. You can refer aad-pod-identity for more information. RBAC disabled AKS cluster kubectl create -f https://raw.githubusercontent.com/Azure/aad-pod-identity/master/deploy/infra/deployment.yaml RBAC enabled AKS cluster kubectl create -f https://raw.githubusercontent.com/Azure/aad-pod-identity/master/deploy/infra/deployment-rbac.yaml Install Helm and run the following to add application-gateway-kubernetes-ingress helm package: RBAC disabled AKS cluster helm init helm repo add application-gateway-kubernetes-ingress https://azure.github.io/application-gateway-kubernetes-ingress/helm/ helm repo update RBAC enabled AKS cluster kubectl create serviceaccount --namespace kube-system tiller-sa kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller-sa helm init --tiller-namespace kube-system --service-account tiller-sa helm repo add application-gateway-kubernetes-ingress https://azure.github.io/application-gateway-kubernetes-ingress/helm/ helm repo update Edit helm-config.yaml and fill in the values for appgw and armAuth # This file contains the essential configs for the ingress controller helm chart # Verbosity level of the App Gateway Ingress Controller verbosityLevel: 3 ################################################################################ # Specify which application gateway the ingress controller will manage # appgw: subscriptionId: <subscription-id> resourceGroup: <resourcegroup-name> name: <applicationgateway-name> ################################################################################ # Specify which kubernetes namespace the ingress controller will watch # Default value is \"default\" # Leaving this variable out or setting it to blank or empty string would # result in Ingress Controller observing all acessible namespaces. # # kubernetes: # watchNamespace: <namespace> ################################################################################ # Specify the authentication with Azure Resource Manager # # Two authentication methods are available: # - Option 1: AAD-Pod-Identity (https://github.com/Azure/aad-pod-identity) armAuth: type: aadPodIdentity identityResourceID: <identity-resource-id> identityClientID: <identity-client-id> ################################################################################ # Specify if the cluster is RBAC enabled or not rbac: enabled: false # true/false ################################################################################ # Specify aks cluster related information. THIS IS BEING DEPRECATED. aksClusterConfiguration: apiServerAddress: <aks-api-server-address> NOTE: The <identity-resource-id> and <identity-client-id> are the properties of the Azure AD Identity you setup in the previous section. You can retrieve this information by running the following command: az identity show -g <resourcegroup> -n <identity-name> Where <resourcegroup> is the resource group in which the top level AKS cluster object, Application Gateway and Managed Identify are deployed. Then execute the following to the install the Application Gateway ingress controller package. helm install -f helm-config.yaml application-gateway-kubernetes-ingress/ingress-azure Jump next to tutorials to understand how you can expose an AKS service over HTTP or HTTPS, to the internet, using an Azure Application Gateway.","title":"Overview"}]}